{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99647121",
   "metadata": {},
   "source": [
    "## Einführung in Pandas\n",
    "\n",
    "In diesem Tutorial wirst du einen Einblick in Pandas erhalten - was ist es, wofür kann es verwendet werden, und wie kannst du es verwenden. Das Tutorial enthält viele Links zur Pandas-Dokumentation. Deine Aufgabe ist es, dich durchzuarbeiten - lass einfach das Code-Skelett so, wie es ist, und ändere Code, wo ** TODO ** steht. Du kannst natürlich jederzeit eine weitere Zelle öffnen und Code ausprobieren - achte einfach darauf, nicht versehentlich eine später verwendete Variable zu überschreiben.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87fa2692",
   "metadata": {},
   "source": [
    "### Installieren und importieren\n",
    "\n",
    "Zuerst möchten wir sicherstellen, dass die beiden Module bereits installiert sind, oder eben installiert werden. Dann werden wir sie importieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7921ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuerst müssen wir pandas importieren. Es ist Konvention, aber nicht strikt notwendig, es als \"pd\" zu importieren.\n",
    "import pandas as pd\n",
    "\n",
    "# Dann importieren wir seaborn. Dieses wird ebenfalls per Konvention als sns importiert\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f84f392c",
   "metadata": {},
   "source": [
    "### Öffnen und Einlesen von Dateien mit csv und Pandas\n",
    "\n",
    "Mit Pandas können wir einfach eine Excel- oder eine CSV-Datei öffnen und in eine Python-lesbare Tabelle übertragen. Dafür verwenden wir die Funktion read_csv oder read_excel. Die Datei kannst du wie unten angegeben einlesen. Achte darauf, dass die Datei im selben Ordner wie deine Code-Datei ist. Wenn dies nicht der Fall ist, musst du den relativen Pfad angeben.\n",
    "\n",
    "Kurz: Wir werden hier .csv-Dateien mit pandas öffnen. Es ist aber auch möglich, .csv-Dateien mit dem Modul csv zu öffnen. Dieses musst du nicht pip-installieren, sondern wird automatisch mit Python installiert. Dafür machst du einfach 'import csv' bei deinen Import-Statements. Weiterführende Informationenn findest du unter dem folgenden Link: https://docs.python.org/3/library/csv.html\n",
    "\n",
    "Damit du dennoch ein ungefähres Verständnis davon erhältst, wie man mit csv arbeiten kannst, und warum Pandas so viel mehr kann, lernst du hier, wie du die Datei öffnen kannst, und wie du über ihre Informationen iterieren kannst.\n",
    "In der nächsten Zelle öffnen wir mit dem Modul csv die csv-Datei. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b305740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erst importieren wir das Modul. es muss nicht pip installiert werden, darum können wir diesen Schritt überspringen.\n",
    "import csv\n",
    "\n",
    "# das with-statement kennst du aus bisherigen Lektionen - es sorgt dafür, dass die Datei wieder im Hintergrund geschlossen wird\n",
    "with open('student_data.csv') as csvfile: \n",
    "    datareader = csv.reader(csvfile, delimiter=\";\")\n",
    "    print(type(datareader)) # damit du weisst, was für einen Datentyp der datareader hat\n",
    "    # Nun iterieren wir über all die Linien und printen diese.\n",
    "    for row in datareader:\n",
    "        print(', '.join(row))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28e47f8e",
   "metadata": {},
   "source": [
    "So iteriert man also mit dem csv-Modul. Wie du sehen kannst, erstellst du mit dem datareader einfach eine Sequenz aller Linien, über die du dann iterieren kannst. Für einfache Operationen, wie beispielsweise die Daten einer .csv-Datei einzulesen und anzuschauen, leicht zu ändern, beispielsweise indem du eine Linie hinzufügst (mit csv.writer()), ist der csv-Reader sicherlich ausreichend. Sobald du aber komplexe Operationen machst, wird es schwieriger: Suchst du beispielsweise nur die Daten, welche in der Spalte 'ISCED Field' (eine der Spalten der Datei) auftauchen, musst du bei der ersten Iteration herausfinden, an welcher Position diese Spalte ist, und dann über jede Zeile iterieren und genau die richtige Spalte auswählen. Klingt kompliziert, ineffizient und/oder herausfordernd? Darum verwenden wir beim genauen Analysieren der Tabellen Pandas. Du findest unten heraus, wie du einfach auf Spalten und andere Informationen zugreifen kannst, ohne über jede Zeile iterieren zu müssen. Dafür möchten wir aber zuerst einmal die Datei öffnen. Auch das geht anders als oben: Wir schreiben einfach pd.read_csv('dateiname.format') (bei einer Excel-Datei: pd.read_excel('dateiname.format')) und ordnen es einer Variable (df, für DataFrame) zu.\n",
    "\n",
    "Bei den Funktionen read_csv() sowie read_excel() ist es, genau wie oben, wichtig, den sogenannten \"delimiter\" zu berücksichtigen. .csv steht für comma-separated values, also durch Kommas getrennte Werte, doch sie können auch anders getrennt sein; beispielsweise durch ein Semikolon (wie im untenstehenden Beispiel). Hier schreibst du einfach als zweites Argument neben dem Dateinamen sep=\";\" und schon klappt es. Oben siehst du, dass man beim Modul csv ein anderes Argument nimmt, namentlich \"delimiter\".\n",
    "\n",
    "Probier in einer neuen Zelle, den Delimiter zu ändern oder ganz wegzulassen. Noch mehr Möglichkeiten (und optionale Argumente) findest du unter dem folgenden Link: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "Die Funktion read_excel brauchst du für diverse Excel-Dateien, die eben nicht das .csv-Format haben, beispielsweise .xls oder .xlsx. Weitere Informationen findest du in der Dokumentation: https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n",
    "\n",
    "Sobald du die Datei geöffnet hast, inspiziere die Daten. Dafür verwendest du einfach df.head() für die ersten fünf Reihen - 5 ist der Default-Wert für wie viele Reihen angezeigt werden sollen. Du kannst aber auch mehr anzeigen, indem du beispielsweise df.head(15) notierst. Zeige hier einfach 10 Zeilen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"student_data.csv\", sep=\";\") \n",
    "\n",
    "# Anmerkung: df.head() wird nur gedruckt, weil es sich hierbei um eine Eigenart des Jupyter Notebooks handelt. Wenn ihr es mit print(df.head()) macht, geht es auch, ist aber nicht so schön (ästhetisch).\n",
    "# ** TODO **\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d18aa44",
   "metadata": {},
   "source": [
    "Statt df.head() für die obersten Reihen kannst du auch df.tail() verwenden. Dies funktioniert genau gleich wie df.head(), zeigt einfach die untersten Reihen an.\n",
    "Zuletzt gibt es noch df.describe(). Dies zeigt einfach Statistiken zu deinen Daten an - die Anzahl, den Durchschnitt, etc. Je nach Daten, mit welchen du arbeitest, hilft dir vielleicht die folgende, etwas mathe-orientiertere Einführung weiter: https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "\n",
    "Im Hintergrund gut zu wissen: Wie du in der obenstehenden Tabelle siehst, haben nur die Spalten Namen. Die Zeilen haben keine, sind also automatisch indexiert (von 0 bis Anzahl Zeilen). Es ist auch möglich, dass diese Zeilen Namen haben - zum Beispiel, wenn ihr genau wisst, was ihr als Index wollt, und es sich hierbei nicht um Zahlen handelt. Da dies eher Ausnahme ist, gehen wir nicht weiter darauf ein; du wirst aber einige Beispiele in der Dokumentation von Pandas finden, wo die Index-Namen beim Erstellen der Tabelle definiert werden, beispielsweise hier: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html\n",
    "\n",
    "Wie kann man aber über die Daten iterieren? Da haben wir so einige Möglichkeiten. Eine davon ist die folgende, zu der du mehr Informationen unter dem folgenden Link findest: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row)\n",
    "\n",
    "# oder, wenn du nicht die ganze Zeile wissen möchtest, sondern nur die Studienfächer mit der jeweiligen Anzahl Masterstudierenden:\n",
    "for index, row in df.iterrows():\n",
    "    print(row[\"ISCED Field\"], row[\"Master\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebba237b",
   "metadata": {},
   "source": [
    "### Gruppieren mit Pandas\n",
    "\n",
    "Mit dieser Tabelle können wir nun so einiges machen. Wir können Daten gruppieren, filtern, sortieren, und all das darstellen. Für die Darstellung verwenden wir hier das Modul seaborn, es gibt aber auch einige weitere Module wie beispielsweise matplotlib (https://matplotlib.org/stable/index.html). Mehr Informationen zu seaborn findest du unter dem folgenden Link: https://seaborn.pydata.org/\n",
    "\n",
    "Wenn du beispielsweise die verschiedenen ISCED-Felder, die es gibt, und die Anzahl Studierender pro Feld anzeigen möchtest, machst du dies mit df.groupby. Hier musst du vor allem eines berücksichtigen: df.groupby gibt ein Objekt aus, das du nicht direkt lesen kannst. Es ist sozusagen ein Zwischenspeicher, der zwar alle Infos enthält, aber einfach nicht schön anzeigbar ist. Du musst weitere Massnahmen ergreifen - beispielsweise die Summe der Gruppen sammeln - um etwas schön übersichtlich anzeigen zu können. Darum überlegst du immer am besten zuerst: Was willst du genau von den Daten, die du gruppierst?\n",
    "\n",
    "Eine einfache Lösung ist es, einfach die Summe der jeweiligen Gruppen anzeigen zu lassen. Dies machst du, wie es unten steht.\n",
    "\n",
    "Genau genommen nimmt der untenstehende Code die Tabelle - df -, findet heraus, welche ISCED Field-Optionen bestehen, und gruppiert die Daten miteinander. Dieser Zwischenspeicher ist sehr theoretisch, weswegen wir in diesem Fall direkt die .sum()-Funktion verwenden. Mit dieser Funktion wird aus den gruppierten Werten eine neue Tabelle gebildet, die aus den verschiedenen ISCED Fields und die Summe all dessen, was wir zählen können, besteht. Das Jahr und das Geschlecht konnten wir nicht addieren, alles andere schon. Dies ist eine Praxis, die allerdings in absehbarer Zeit nicht mehr funktionieren wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sums_by_isced = df.groupby('ISCED Field').sum()\n",
    "\n",
    "sums_by_isced.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97d7177b",
   "metadata": {},
   "source": [
    "Da in der Zukunft das automatische Summieren der numerischen Werte deaktiviert wird, ist es besonders für dich als \"Neuling\" wichtig, dich daran zu gewöhnen, dich an die gewünschte Praxis zu gewöhnen. Beispielsweise wollen wir hier nur wissen, wie viele Studierende über die Jahre pro Feld im Bachelor waren - Zahlen zum Doktorat und Master interessieren uns nicht. In diesem Fall ergänzen wir den Code um die Kolonnen, die er berücksichtigen soll. Alles, was uns nicht interessiert, lassen wir weg. Wichtig: Wenn dich mehrere Spalten interessieren, schreibst du es wie folgt: df.groupby('ISCED Field')[['Bachelor', 'Master']].sum(), du setzt also die Spaltennamen in eine Liste, und greifst danach mit dem zweiten Paar eckiger Klammern darauf zu - du hast also auf beiden Seiten der gewünschten Spalten je zwei eckige Klammern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_by_isced_ba = df.groupby('ISCED Field')['Bachelor'].sum()\n",
    "\n",
    "sums_by_isced_ba.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c48b8d45",
   "metadata": {},
   "source": [
    "### Bestimmte Informationen einer bestimmten Spalte abrufen\n",
    "Manchmal wollen wir aber auch nur von einer einzigen Spalte Informationen holen, und diese nutzen. Dafür nutzen wir df.loc. Diese Funktion nimmt, ähnlich wie die .groupby Funktion, die Spalte, von der du Informationen holen willst, als Argument. Du kannst erneut mit df.head() überprüfen, welche Spalten bestehen, und welche Werte ihnen grundsätzlich zugeordnet werden. Sobald du weisst, wie die Spalte heisst, die du benötigst, verwendest du df.loc['Spaltenname']. Denk auch hier daran, dass der Spaltenname ein String ist, und entsprechend geschrieben werden muss. Du kannst aber auch mehr als nur Spaltennamen mit df.loc finden. Unter dem folgenden Link findest du mehr Informationen: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "\n",
    "Wichtig: bei df.loc[] verwenden wir nicht die üblichen runden Klammern wie bei vielen anderen Funktionen. Hier verwenden wir direkt [], also die eckigen Klammern.\n",
    "\n",
    "Beispielsweise möchten wir die Verteilung der Studierenden über das Jahr 2021/2022 über die verschiedenen Studienfelder wissen. Hier definieren wir erst einmal mit df.loc[], worauf wir zugreifen möchten.\n",
    "\n",
    "Im untenstehenden Code möchten wir wissen, wie die Verteilung über die verschiedenen Felder im letzten erfassten Jahr (2021/2022) war. Dafür definieren wir erst, welche Spalte uns im df.loc interessiert. Mit df[\"Year\"] greifen wir auf die korrekte Spalte - die \"Year\" heisst - zu. Diese muss \"2021/22\" exakt entsprechen. Da dies eine Kondition ist, setzen wir sie in runde Klammern. Die eingeklammerte Kondition setzen wir also in df.loc, damit diese Informationen einfach in der Tabelle gefunden werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = df.loc[(df[\"Year\"]==(\"2021/22\"))]\n",
    "year_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45afab92",
   "metadata": {},
   "source": [
    "Nun haben wir oben mit df.loc die gewünschte Spalte ausgewählt und einer Variable (year_df) zugeordnet. Sobald wir die Spalte also ausgewählt haben, können wir die Summe aller Werte einfach mit der sum()-Funktion herausholen. Die sum()-Funktion hier bezieht sich auf die gewünschten Spalten, da in der Zukunft das automatische Summieren deaktiviert wird. Es werden einfach alle Werte zusammengezählt. Du gehst also wie folgt vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df.groupby(\"ISCED Field\").sum()\n",
    "\n",
    "year_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c87d5819",
   "metadata": {},
   "source": [
    "### Filtern der Spalten\n",
    "\n",
    "Mit der df.filter()-Funktion kannst du deine Tabelle einfach nach bestimmten Werten durchfiltern. Diese können in Spalten oder Zeilen vorkommen - wobei bei den Zeilen wichtig ist: df.filter() durchsucht die Zeilennamen, welche den Index repräsentieren. Wenn du also den Index nicht überschrieben hast und dort einfach Zahlen drin hast, kannst du es zwar nach diesen Zahlen durchsuchen, ob dies aber sinnvoll ist, muss anderweitig diskutiert werden.\n",
    "\n",
    "Die Tabellenwerte - also beispielsweise die Zahl der Studierenden - kannst du so nicht durchsuchen. \n",
    "\n",
    "Mehr Informationen zu dieser Funktion findest du unter dem folgenden Link: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html\n",
    "\n",
    "Wir möchten also beispielsweise herausfinden, wie sich die - notabene: binäre - Geschlechtsverteilung über die ISCED Fields im Bezug aufs Doktorat genau verhält. Dafür definieren wir erst einmal, wonach genau wir filtern möchten. Wir möchten sowohl das ISCED Field, das Geschlecht, als auch die Anzahl Doktorierender wissen. Dann gruppieren wir nach Doktorat. In diesem Fall berücksichtigen wir die einzelnen Jahre nicht, die Zahlen beziehen sich also auf die Doktorierenden über die Jahre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_gender_df = df.filter(items=[\"ISCED Field\", \"Sex\", \"Doctorate\"]).groupby(\"ISCED Field\")\n",
    "\n",
    "by_gender_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90820687",
   "metadata": {},
   "source": [
    "### Lernkontrolle\n",
    "\n",
    "Überprüfe, indem du die Frames wie oben drucken lässt (Variable am Ende des Blocks schreiben), ob du die Aufgabe erfüllst.\n",
    "\n",
    "Dich interessiert es, wie viele Masterstudierende und Doktorierende es über die Jahre gab, und wer von ihnen auf welcher Stufe (Master, Doktorat) war. Dafür gruppierst du erst mal mit der .groupby-Funktion, wonach du sortieren möchtest - in diesem Fall also das Jahr. Bedenk, zu vermerken, welche Gruppen, die dich interessieren - beispielsweise die Stufen Bachelor, Master und Doktorat. Mit df.head() konntest du den ungefähren Aufbau der Tabelle einsehen, damit du weisst, wie die jeweiligen Spalten heissen. \n",
    "\n",
    "Nun interessiert es dich, wie sich die Geschlechtsverteilung über die Jahre verändert hat. Hierfür filterst du nach Geschlecht und Jahr.\n",
    "\n",
    "Als letztes möchtest du wissen, wie viele Studierende es im Jahr 2012/2013 gab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08deaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lös die obenstehende Aufgabe hier und in folgenden, neuen Zellen.\n",
    "# ** TODO **"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75708354",
   "metadata": {},
   "source": [
    "### Visualisierung\n",
    "\n",
    "Neben reinem Tabellen-Inspizieren können wir auch Graphen kreieren. Dafür verwenden wir seaborn (https://seaborn.pydata.org/). Dieses haben wir oben bereits - als sns - importiert.\n",
    "\n",
    "Seaborn hat viele Plot-Optionen. Eine Übersicht findest du unter folgendem Link: https://seaborn.pydata.org/tutorial/function_overview.html. Wir werden uns hier auf den lineplot und den barplot konzentrieren. Je nach Bedürfnis und Wunsch kannst du auch weitere Plots erstellen.\n",
    "\n",
    "Wir entscheiden also zuerst, welchen Plot wir wählen, und auf welchem Datensatz dieser basieren soll, indem wir dem Argument \"data\" den Namen des Datensatzes geben. Unten entscheiden wir uns erst mal für einen Lineplot (https://seaborn.pydata.org/generated/seaborn.lineplot.html). Im ersten Beispiel verwenden wir einen neuen Datensatz, der sich gut für Linienplots eignet - die Summe aller Studierenden, über die Jahre verteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = df.groupby(\"Year\")[[\"Bachelor\", \"Master\", \"Doctorate\"]].sum()\n",
    "\n",
    "sns.lineplot(data=sum_df)\n",
    "sns.set(rc={'figure.figsize':(12,10)}) # diese Linie brauchen wir, um die Grösse der Grafik richtigzuschrauben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b354f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = df.loc[(df[\"Year\"]==(\"2021/22\"))]\n",
    "year_df.groupby(\"ISCED Field\").sum()\n",
    "\n",
    "# Damit x=\"sum\" korrekt interpretiert werden kann, müssen wir dies klar zuordnen. Dies machen wir mit dem folgenden Befehl:\n",
    "year_df = year_df.assign(sum = year_df['Bachelor'] + year_df['Master'] + year_df['Doctorate'])\n",
    "\n",
    "sns.barplot(x=\"sum\", y=\"ISCED Field\", data=year_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7ab0631",
   "metadata": {},
   "source": [
    "Du merkst: Einen Plot zu machen und einigermassen gut aussehen zu lassen, ist mit seaborn erstaunlich einfach. Es gibt enorm viele weitere Optionen, die du anwenden kannst, um die Plots mehr nach deinem Geschmacka usrichten zu lassen. Wenn du alle Optionen vom Linienplot willst, findest du diese unter https://seaborn.pydata.org/generated/seaborn.lineplot.html. Mehr Informationen zum Barplot findest du entsprechend unter https://seaborn.pydata.org/generated/seaborn.barplot.html. Auf der Webseite von Seaborn findest du noch mehr Plots, und mehr Optionen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a4a0ff3",
   "metadata": {},
   "source": [
    "### Lösung der Lernkontrolle\n",
    "\n",
    "Überprüfe, indem du die Frames wie oben drucken lässt (Variable am Ende des Blocks schreiben), ob du die Aufgabe erfüllst.\n",
    "\n",
    "Dich interessiert es, wie viele Masterstudierende und Doktorierende es über die Jahre gab, und wer von ihnen auf welcher Stufe (Master, Doktorat) war. Dafür gruppierst du erst mal mit der .groupby-Funktion, wonach du sortieren möchtest - in diesem Fall also das Jahr. Bedenk, zu vermerken, welche Gruppen, die dich interessieren - beispielsweise die Stufen Bachelor, Master und Doktorat. Mit df.head() konntest du den ungefähren Aufbau der Tabelle einsehen, damit du weisst, wie die jeweiligen Spalten heissen. \n",
    "\n",
    "Nun interessiert es dich, wie sich die Geschlechtsverteilung über die Jahre verändert hat. Hierfür filterst du nach Geschlecht und Jahr.\n",
    "\n",
    "Als letztes möchtest du wissen, wie viele Studierende es im Jahr 2012/2013 gab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd56b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_data.csv', sep=\";\")\n",
    "\n",
    "grp_by_year = df.groupby(\"Year\")[['Year', 'Master', 'Doctorate']]\n",
    "\n",
    "grp_by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df.groupby([\"Year\", \"Sex\"])[['Bachelor', 'Master', 'Doctorate']].sum() # dies illustriert bereits alle Studierenden nach Stufe, Jahr und Geschlecht.\n",
    "\n",
    "# Mit folgenden Zusatzschritten betrachten wir einfach die Gesamtsumme aller Studierenden nach Geschlecht.\n",
    "\n",
    "filtered = filtered.assign(sum = filtered['Bachelor'] + filtered['Master'] + filtered['Doctorate'])\n",
    "\n",
    "filtered = filtered.filter(items=['Year', 'Sex', 'sum'])\n",
    "\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_year = df.loc[(df[\"Year\"]==\"2012/13\")].sum()\n",
    "\n",
    "specific_year.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c11e1ca9",
   "metadata": {},
   "source": [
    "Gratuliere! Du hast sowohl die Grundlagen vom Manipulieren von Tabellen als auch die Grundlagen vom graphischen Darstellen derer Inhalte gelernt. Mit den angegebenen Links kannst du auch mit deinen eigenen Daten herumexperimentieren."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
