%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% HEADER
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,oneside, 12pt]{report}
% Alternative Optionen:
%	Papiergrösse: a4paper / a5paper / b5paper / letterpaper / legalpaper / executivepaper
% Duplex: oneside / twoside
% Grundlegende Fontgrössen: 10pt / 11pt / 12pt


%% Deutsche Anpassungen %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[numbers]{natbib}
\usepackage{lmodern} %Type1-Schriftart für nicht-englische Texte
\usepackage{color,soul} %Highlight
\usepackage{acronym} % Abkürzungen
\usepackage[toc,page]{appendix}
\usepackage{pdfpages}
\usepackage{subcaption} %Bilder nebeneinander
\usepackage{rotating} %Tabelle Hochkant
\usepackage{color, colortbl}
\usepackage{fancyvrb} %Text File einbinden
\usepackage{embedfile}[2020/04/01]

%% Packages für Grafiken & Abbildungen %%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx} %%Zum Laden von Grafiken
%\usepackage{subfig} %%Teilabbildungen in einer Abbildung
%\usepackage{pst-all} %%PSTricks - nicht verwendbar mit pdfLaTeX

%% Packages für Formeln %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}


%% PDF-A Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[hyphens]{url}
\usepackage[hidelinks,pdfa]{hyperref}
\usepackage{hyperxmp}[2020/03/01]
\hypersetup{breaklinks=true}
\urlstyle{same}
\title{Leistungsnachweis 01}
\author{Andrés Baumeler}
\embedfile[afrelationship={/Source},ucfilespec={\jobname.tex},mimetype={application/x-tex}]{\jobname.tex}
\hypersetup{%
    pdflang=la,
    pdfapart=3, %set to 1 for PDF/A-1
    pdfaconformance=B
}

% %Create an OutputIntent in order to correctly specify colours
\immediate\pdfobj stream attr{/N 3} file{sRGB.icc}
\pdfcatalog{%
  /OutputIntents [
    <<
      /Type /OutputIntent
      /S /GTS_PDFA1
      /DestOutputProfile \the\pdflastobj\space 0 R
      /OutputConditionIdentifier (sRGB)
      /Info (sRGB)
    >>
  ]
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Anmerkungen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Zu erledigen:
% 1. Passen Sie die Packages und deren Optionen an (siehe oben).
% 2. Wenn Sie wollen, erstellen Sie eine BibTeX-Datei
%    (z.B. 'literatur.bib').
% 3. Happy TeXing!
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optionen / Modifikationen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Pfad für Bilder
\graphicspath{ {../img/} }

% redefine \VerbatimInput
\RecustomVerbatimCommand{\VerbatimInput}{VerbatimInput}%
{fontsize=\footnotesize,
 %
 frame=lines,  % top and bottom rule only
 framesep=2em, % separation between frame and text
 rulecolor=\color{Gray},
 %
 label=\fbox{\color{Black}Dokumentation.txt},
 labelposition=topline,
 %
 commandchars=\|\(\), % escape character and argument delimiters for
                      % commands within the verbatim
 commentchar=!        % comment character
}

%% Zeilenabstand %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{setspace}
%\singlespacing        %% 1-zeilig (Standard)
\onehalfspacing       %% 1,5-zeilig
%\doublespacing        %% 2-zeilig

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% DOKUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\definecolor{Gray}{gray}{0.9}
\definecolor{LGray}{gray}{0.8}

\pagestyle{empty} %%Keine Kopf-/Fusszeilen auf den ersten Seiten.


%% Deckblatt %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{titelseite}


%% Inhaltsverzeichnis %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\tableofcontents %Inhaltsverzeichnis
\cleardoublepage %Das erste Kapitel soll auf einer ungeraden Seite beginnen.

\pagestyle{plain} %%Ab hier die Kopf-/Fusszeilen: headings / fancy / ...


%% Kapitel / Hauptteil des Dokumentes %%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ==> Einleitung
\chapter{Einleitung}\label{sec:motivation}
Digitalisierung von historischen Schriften ist ein umfassender Prozess welcher aus vielen Schritten besteht. \ac{OCR} nimmt dabei eine wichtige Rolle ein. \ac{OCR}  wird im Digitalisierungsprozess dazu verwendet Text von digitalisierten Dokumenten maschinenlesbar zu machen. Dadurch können die Dokumente im Volltext durchsucht werden und der Text für weitere Analysen verwendet werden. In den letzten Jahren konnte die Qualität der OCR Resultate durch den Einsatz von Verfahren aus dem Maschinenlernen, insbesondere neuronale Netzwerke, verbessert werden. So ist es heute möglich auch handgeschriebenen Text automatisch zu erkennen. Dies ermöglicht die Retrodigitalisierung von historischen Schriften in einem vorher nie dagewesenen Volumen. 

Der Einsatz von neuronalen netzwerken setzt voraus, dass entsprechende Trainingsdaten in genügender Qualität und Quantität verfügbar sind um die eingesetzten neuronalen Netzwerke zu trainieren. Das Ergebnis des Trainingsvorgangs wird in Modellen gespeichert. Diese Modelle können für verschiedene Szenarien wiederverwendet werden und ersparen ein erneutes Trainieren des neuronalen Netzwerks. 
Für die Volltexterkennung von historische Schriften haben sich dabei zwei Lösungen heruaskristallisiert: OCR-D und Transkribus. Diese zwei Lösungen, insbesondere der Umgang mit Trainngsdaten und Modellen
sollen in diesem Text verglichen werden. OCR-D setzt auf einen open Source und verteilten Ansatz während Transkribus auf einen closed Source und zentralisierten Ansatz setzt.

Im Ersten Kapitel wird aufgezeigt wie die Volltexttransformation abläuft und wo im Prozess \ac{NN} eingesetzt werden können. Weiter wird erläutert wie Neuronale Netzwerke trainiert werden und welche Rolle dabei die verwendeten Trainingsdaten spielen. Im Zweiten Kapitel werden die Frameworks OCR-D und Transkribus vorgestellt. Dabei wird aufgezeigt wie die beiden Frameworks mit Trainingsdaten und trainierten Modellen umgehen. In desem Abschnitt wird auch auf die Vor- und Nachteile der beiden Lösungsansätze eingegangen. Es handelt sich hierbei nicht um einen wissenschaftlichen Vergleich sondern um einen Erfahrungsbericht aus der Anwendung der zwei Lösungen im Privatbereich. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Grundlagen
\chapter{Grundlagen}\label{sec:grundlagen}
\section{Volltexttransformation}
Der Prozess der Volltexttransformation besteht aus mehreren Schritten wovon die eigentliche Texterkennung nur einer ist. Je nach Ausgangslage- und Material sind dabei unterschiedliche Schritte notwendig. Ein Beispielhafter Prozess zur Volltextransformation beinhaltet die Schritte:
\begin{itemize}\itemsep=0.5pt
  \item Seitentrennung
  \item Aufbereiten der einzelnen Seitentrennung
  \item Optische Layout Erkennung und Segmentierung der Seiten
  \item Aufbereiten der einzelnen Segmente
  \item Unterteilen der einzelnen Segmente in Textzeilen
  \item Aufbereiten der einzelen Textzeilen
  \item Texterkennung auf den einzelnen Textzeilen
  \item Zusammenfügen der erkannten Texte
  \item Klassifizierung der erkannten Regionen
  \item Dokumentanalyse und Export
  \item Nachbearbeitung und ggf. manuelle Kontrolle und Korrektur der Resultate
\end{itemize}
Die Unterteilung in einzelne Textzeilen ist notwendig, da die eingestzten \acp{NN} die Texterkennung auf Zeilenebene durchführen. Für die meisten dieser Schritte können bzw. werden \acp{NN} eingesetzt. Der Fokus des Vergleichs wird aber auf den Schritten Segmentierung und Texterkennung liegen.

\section{Einsatz von neuronalen Netzwerken für Volltexttransformation}
\acp{NN} sind ein Subset des Bereichs \ac{ML}. Neuronal Netze werden verwendet, um Muster in Daten zu erkennen und dadruch Probleme zu lösen. In den letzten Jahren hat die Entwicklung von neuronalen Netzen enorme Fortschritte gemacht, insbesondere durch den Einsatz von Deep Learning, einer Variante des neuronalen Netzes, die mehrere Schichten von Netzwerken verwendet, um komplexe Aufgaben auszuführen. Neuronale Netzwerke bestehen aus einer Eingangs- und Ausgangsschicht. Dazwischen gibt es eine oder mehrere sog. versteckte Schichten. In jeder Schicht gibt es Knoten (künstliche Neuronen) welche mit einem oder mehreren Knoten aus anderen Schichten verbunden sind. Jede Schicht verarbeitet Eingabedaten und gibt Ausgabedaten an die nächste Schicht weiter bis die Daten am Schluss auf der Ausgabeschicht landen. \cite{ibmnn}

Bei der Volltexterkennung können \ac{NN} eingesetzt werden um die Layouterkennnung, Segmentierung und Texterkennung der einzelnen Segmente durchzuführen. Dafür sind für jeden Schritt andere Netzwerke mit anderne Trainingsdaten notwendig.


\section{Trainieren von neuronalen Netzwerken} 
Trainingsdaten sind eine Sammlung von Beispielen, die zum Training von künstlichen Intelligenz Modellen verwendet werden. Sie bestehen aus Eingabe- und Ausgabedaten. Die Qualität der Trainingsdaten hat einen grossen Einfluss auf die Leistung des Modells, da sie dem Modell beibringen, Muster zu erkennen und Entscheidungen auf der Grundlage dieser Muster zu treffen.

Ground Truth (zu Deutsch: Wahrheit oder Wirklichkeit) ist ein Begriff der in der künstlichen Intelligenz verwendet wird um die korrekten Ausgaben für eine Eingabe zu beschreiben. Ground Truth sind Trainingsdaten für welche die Eingangs - und Ausgangsdaten verifiziert wurden. Das bedeuetet zu einem Eingangswert ist der korrekte Ausgangswert fesgehalten. Bei der Texterkennung können Trainingsdaten beispielsweise aus Bilder von Textzeilen und dem auf dem Bild enthaltenen Text in maschinenlesbarer Form bestehen. Diese Ground Truth muss meist durch mühsame manuelle Arbeit erstellt werden denn nur so kann sichergestellt werden, dass das Modell auf einer korrekten Grundlage trainiert wird.

Im Kontext der neuronalen Netzwerke bezeichnet ein Modell die Konfiguration eines \ac{NN}. Zur Konfiguration gehören die Anzahl und Anordnung der Neuronen, die Verbindungen unter den Neuronen sowie die Gewichtung dieser Verbindungen. Beim Training werden diese Werte stetig verändert um die Ausgabendaten des \ac{NN}

Ein Netzwerk wird trainiert, indem es mit Trainingsdaten gefüttert wird um daraus Ausgangsdaten gemäss der aktuellen Konfiguration zu produzieren. Die Ausgabedaten werden mit den Eingabedaten verglichen und das Netzwerk wird angepasst. Im Zuge dieser Anpassung können etwa Verbindungen zwischen den Neuronen gelöscht oder neu angelegt werden. Auch die Gewichtung der einzelnen Verbindungen kann angepasst werden. Diese Anpassungne erfolgen automatisiert und semi-zufällig. Ein Training geht über mehrere Durchläufe (sogenannte Epochen). Es gibt verschiedene Metriken um zu messen wie gut ein Modell an den korrekte Ausgangsdaten ist.

Wenn die Trainingsdaten nicht repräsentativ für das zu lösende Problem sind oder schlecht gelabelt wurden, kann das Modell fehlerhaft trainiert werden und schlechte Vorhersagen treffen. Daher ist es wichtig, qualitativ hochwertige Trainingsdaten zu haben, um ein leistungsfähiges Modell zu trainieren.


\section{Handhabung Trainingsdaten und Modelle}
Aufzeigen wie Trainingsdaten und Modelle Strukturiert sind.  Aufzeigen welche Methoden es heute gibt um Trainingsdaten und Modelle zu verwalten.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Vergleich
\chapter{Vergleich des Umgangs mit Trainingsdaten und Modellen}\label{sec:vergleich}

\section{OCR-D}
OCR-D wird im Rahmen des DFG-Projekts OCR-D entwickelt und hat zum Ziel die Volltexttransformation Drucken aus dem Deutschen Sprachraum des 16. bis 18. Jahrhunderts konzeptionell und technisch vorzubereiten \cite{standOCR-D}.  Das OCR-D Framework ist OpenSource. Das beudeutet der Source Code ist öffentlich einsehbar und kann von interssierten Personen auch modifiziert werden. OCR-D verwendet zur Verwaltung des Source Code ein Repository auf GitHub.\cite{ocrdgithub}

OCR-D ist ein Framwork welches mehrere Softwaremodule verbindet. Durch diese Modulare herangehensweise können die einzelnen Schritte im OCR Workflow druch unabhängige Softwarekomponenten abgedeckt werden. Diese Softwarekomponenten werden im OCR-D Framework als Prozessoren bezeichnet. Für den \ac{OCR} Prozessor können die OCR Engines Tesseract, Ocropus, Kraken und Calamari eingesetzt werden. Der Export der OCR Resultate geschieht im ALTO Format.

Die Verwendung von OCR-D ist kostenfrei. Unterstützung beim Setup und der Anwendung kann aus der OCR-D Community bezogen werden. 

Der Anwendungsbereich für OCR-D sind Institutionen welche in der Lage sind die Lösung selbst zu Installieren und zu Konfigurieren. Die Installation kann dabei nativ oder via Docker Container erfolgen. Bei der nativen Installation wird das Programm vom Source Code gebaut und installiert. Dies geschieht mit den Werkzeugen make. Bei der Installation via Docker wird eine eine Maschine oder Server mit einer Docker Engine vorausgesetzt. Das Docker image wird dann via docker pull vom Repository geladen. Der Export der OCR Resultat ist als PDF oder im ALTO Format möglich.
\section{Transkribus}
Transkribus ist eine kommerzielle Plattform für Texterkennung, Transkription und das Durchsuchen von historischen Dokumenten. Transkribus wurde im Rahmen des Horizon 2020 EU-Projekts READ von einem Konsortium führender Forschungsgruppen aus ganz Europa unter der Leitung der Universität Innsbruck entwickelt. Die Plattform wird von der Genossenschaft READ-COOP betrieben und weiter entwickelt. \cite{readcoopabout} 

Für die einzelnen Schritte Layout- und Strukturerkennung sowie Texterkennung setzt Transkribus auf Maschinelles Lernen. \cite{transkribus}

Für die Texterkennung muss bei Transkribus bezahlt werden. Die Bezahlung erfolgt mit Credits welche vorgängig über den Transkribus Shop gekauft werden müssen. \cite{transkribuspricing}

Um Transkribus anzuwenden ist keine Installation notwendig. Dokumente können direkt über die Webseite von Transkribus unter \url{https://transkribus.ai} möglich. Dabei werden die Bildaten an die Server von Trankribus übermittelt und durchlaufen dort die Schritte für die Volltexttransformation. Für kleinere Mengen an Seiten entfällt somit eine lokale Installation, es wird lediglich ein aktueller Browser vorausgesetzt.

Für grössere Volumen bietet Transkribus auch eine Client Anwendung an. Dieser sogennnante Expert Client ist eine Eclipse basierte Java Applikation welche lokal installiert wird. Über diesen Client lassen sich eine vielzahl Parameter für den Prozess der Volltexttransformation einstellen. Der Client dient auch dazu Bilder zu Transkribus Servern hochzuladen. \cite{transkribusclient}

Für die Anbindung an andere System beitet Transkribus auch ein REST API zum Hochladen von Dokumenten und zum konfigurieren der Volltextransformation. \cite{transkribusapi}. 

Die Bearbeitung der Bilder erfolgt aber auch in diesem Verfahren auf den Servern von Transkribus.

\section{Umgang mit Trainingsdaten}
Aufzeigen wie die beiden Framworks mit Trainingsdaten umgehen. Wie kann neue Ground hinzugefügt werden.

Bei OCR-D liegt es in der Verantwortung der Anwender die Trainingsdaten zu verwalten. 

Transkribus bieted die Möglichkeit eigene Bilder zum Training hochzuladen. Für diese Trainingsdaten können dann Zugriffsrechte vergeben werden. So ist es möglich ein Modell zwar öffentlich zugänglich zu machen, die zugrundeliegenden Trainingsdaten aber privat zu halten. Für die Modelle welche von Transkribus selbst veröffentlicht wurden, sind die Trainingsdaten nicht zugänglich.

\section{Umgang mit Modellen}
Aufzeigen wie die beiden Frameworks mit Modellen umgehen. Wie können Modelle wieder verwendet werden. Wie können trainierte Modelle geteilt werden. Welche Daten von einem Modell sind einsehbar. Kann ein Modell weiter trainiert werden.

Bei OCR-D sind die Modelle welcher erstellt werden immer unter der Kontrolle der erstellenden Institution. Da es sich um Open Source Softeare handelt ist offen einsehbar wie ein Modell zustande kommt. Da OCR-D ein Framwork ist welches verschieden Prozessoren für die Texterkennung einsetzt müssen Modelle für die einzelnen Modelle separat traniniert werden. Die einzelnen Modelle sind untereinander auch nicht zwingendermassen kompatibel. Beispielsweise ist ein Modell welches für die Ocropus OCR Engine trainiert wurde nicht zwingendermassen kompatibel für die Tesseract OCR Engine. Von diesen Einschränkungen abgesehen, können Modelle aber offen miteinander geteilt werden. Modelle werden als ZIP Container ausgetauscht und können auf einer passenden Umgebung weiter verwendet werden.

Die folgenden Informationen beziehen sich auf den Transkribus Expert Client in der Version 1.24.2. Tranksribus unterscheided bei Modellen zwischen Modellen für die Layouterkennungen und Modellen für die Texterkennung. Bei den Modellen für die Texterkennung können Modelle entweder für die CITLab Engine oder für die PyLaia Engine trainiert werden. Da bei Transkribus die Verarbeitung immer auf der Platform und damit auf den Servern von Transkribus stattfinden, liegen auf trainierte Modelle auf der Platform. Transkribus bietet die Möglichkeit die Zugriffsrechte auf einem Modell anzupassen. So ist es möglich ein Modell öffentlich zu teilen und allen Benutzer der Platform den Zugriff auf das Modell zu ermöglichen. Ein Export des Modells, etwa zur Verwendung in einer eigenen Installation oder als Backup, ist aber nicht möglich. Die Rohdaten zu einem Modell sind nicht einsehbar. Transkribus zeigt auf der Seite zu einem Modell eine Übersicht mit Statistiken und Informationen zu einem Modell. So ist ersichtlich welche Trainingsdaten verwendet wurden und wie viele Epochen trainiert wurden.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ==> Schluss
\chapter{Schluss}\label{sec:schluss}
OCR-D und Transkribus lösen ähnliche Probleme mit unterschiedlichen Ansätzen. OCR-D setzt auf Open Source während Transkribus eine mehrheitlich geschlossene Plattform ist.

Die Einstiegshürden für Transkribus sind gerade für Institutionen mit geringem Informatikverständnis um einiges tiefer als bei OCR-D. Bei Transkribus reicht eine Registierung aus um erste Dokumente über den Browserclient zu digitalisieren. 
Ein initial Setup von OCR-D benötigt mehr technisches Verständnis, bietet dann aber mehr Konfigurations- und Anpassungsmöglichkeiten. Der Vorteil von OCR-D ist, dass sämtliche verwendeten Komponenten Open Source sind. Dadurch kann wird die Abhängigkeit von einer Institution verringert. Der Prozess kann zudem transparent dokumentiert werden indem die verwendeten Prozessoren inklusiver Versionen und Parameter notiert werden. 

Bei der Handhabung von Trainingsdaten zeigen sich Unterschiede zwischen den zwei Framworks. Bei OCR-D sind die trainierten Modelle offen zugänglich und können geteilt werden. Hier stellen sich Probleme der Kompatbilität. Modelle eines Prozessors sind nicht unbedingt mit einem anderen Prozessor nutzbar. Auch bei unterschiedlichen Prozessor- oder Engine Versionen kann es zu Inkompatibilitäten kommen. Bei Transkribus existiert zwar die Möglichkeit Modelle zu teilen. Der Zugriff auf die Rohdaten eines Modells ist aber nicht möglich. Das verhindert den Einsatz eines Modells auf einener anderen Plattform. Zugleich wird durch den Ansatz von Transkribus die Komplexität reduziert. Die Benutzenden brauchen sich keine Gedanken um die Kompatbilität der Modelle zu machen. Transkribus bietet die Möglichkeit Zugriffsrechte für Trainingsdaten und Modelle separat zu kontrollieren. Das ermöglicht es ein Modell zu veröffentlichen auch wenn die zugrunde liegenden Trainingsdaten etwa aus rechtlichen Gründen nicht veröffentlicht werden dürfen.

Beide Plattformen bieten einen guten Funktionsumfang und lieferen beeindruckende Resultate in der Volltexttransformation. Sowohl der Open Source Ansatz von OCR-D als auch der Ansatz einer kommerziellen Plattform bei Transkribus machen Sinn. Beide Ansätze kommen mit ihren jeweiligen Vor- und Nachteilen. Es kann nich abschliessend gesagt werden, welcher der zwei Ansätze besser ist. In der Evaluationsphase eines Digitalisierungsprojektes sollte deshalb sorgfälltig anhand der Anfoderungen des Projekts und der durchführenden Institution entschieden werden welche Lösung die geeignetere ist.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LITERATUR UND ANDERE VERZEICHNISSE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Ein kleiner Abstand zu den Kapiteln im Inhaltsverzeichnis (toc)
\addtocontents{toc}{\protect\vspace*{\baselineskip}}

%% Abkürzungen
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Abkürzungen}
\chapter*{Abkürzungen}
\begin{acronym}[Abkürzungen]
	\acro{OCR}{Optical Character Recognition}
    \acro{ML}{Maschinenlernen}
    \acro{NN}{Neuronales Netzwerk}
    \acroplural{NN}[NN]{Neuronale Netzwerke}
\end{acronym}

%% Literaturverzeichnis %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ==> Eine Datei 'literatur.bib' wird hierfür benötigt.
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Literaturverzeichnis}
%\nocite{*} %Auch nicht-zitierte BibTeX-Einträge werden angezeigt.
\Urlmuskip=0mu plus 1mu\relax
\bibliographystyle{plainnat} %Art der Ausgabe: plain / apalike / amsalpha / ...
\bibliography{literatur} %Eine Datei 'literatur.bib' wird hierfür benötigt.
\end{document}